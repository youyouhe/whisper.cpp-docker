version: '3.8'

services:
  whisper-gpu0:
    build:
      context: .
      dockerfile: Dockerfile.server.cuda
    image: whisper-server:latest
    container_name: whisper-gpu0
    environment:
      - GPU_DEVICE=0
      - THREADS=4
      - PORT=8080
    volumes:
      - ./audio:/app/audio
      - ./models:/app/models
    ports:
      - "8080:8080"
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  whisper-gpu1:
    build:
      context: .
      dockerfile: Dockerfile.server.cuda
    image: whisper-server:latest
    container_name: whisper-gpu1
    environment:
      - GPU_DEVICE=1
      - THREADS=4
      - PORT=8081
    volumes:
      - ./audio:/app/audio
      - ./models:/app/models
    ports:
      - "8081:8081"
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['1']
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # 负载均衡器
  nginx:
    image: nginx:latest
    container_name: whisper-nginx
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - whisper-gpu0
      - whisper-gpu1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s