# 构建阶段 - 使用 CUDA 12.9.0
FROM nvidia/cuda:12.9.0-devel-ubuntu20.04 AS builder

# 避免交互式安装
ENV DEBIAN_FRONTEND=noninteractive

# 安装所有依赖
RUN apt-get update && \
    apt-get install -y \
        build-essential \
        git \
        wget \
        pkg-config \
        curl \
        software-properties-common \
        ffmpeg \
        libfftw3-dev \
        libfftw3-single3 \
        libfftw3-double3 && \
    wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2>/dev/null | gpg --dearmor - | tee /etc/apt/trusted.gpg.d/kitware.gpg >/dev/null && \
    apt-add-repository 'deb https://apt.kitware.com/ubuntu/ focal main' && \
    apt-get update && \
    apt-get install -y cmake && \
    rm -rf /var/lib/apt/lists/*

# 创建工作目录
WORKDIR /app

# 复制源代码
COPY . /app

# 配置和编译（启用 CUDA 支持，指定 GTX 1080/2080 架构）
RUN cmake -B build \
    -DGGML_CUDA=1 \
    -DCMAKE_CUDA_ARCHITECTURES="61;75" \
    -DWHISPER_BUILD_SERVER=ON \
    -DCMAKE_BUILD_TYPE=Release \
    && cmake --build build -j $(nproc)

# 运行阶段 - 使用 CUDA 12.9.0 运行时
#FROM nvidia/cuda:12.9.0-runtime-ubuntu20.04

# 避免交互式安装
ENV DEBIAN_FRONTEND=noninteractive

# 安装运行时依赖
RUN apt-get update && apt-get install -y \
    ffmpeg \
    libfftw3-single3 \
    libfftw3-double3 \
    curl \
    && rm -rf /var/lib/apt/lists/*

# 设置环境变量
ENV LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
ENV PATH=/usr/local/cuda/bin:$PATH

# 创建非特权用户
RUN useradd -m -u 1000 whisperuser
USER whisperuser

# 创建工作目录
WORKDIR /app

# 从构建阶段复制二进制文件
COPY --from=builder /app/build/bin/whisper-server ./build/bin/whisper-server
COPY --from=builder /app/models/download-ggml-model.sh ./models/download-ggml-model.sh
COPY --from=builder /app/models/download-vad-model.sh ./models/download-vad-model.sh

# 下载预训练模型
RUN ./models/download-ggml-model.sh large-v3-turbo
RUN ./models/download-vad-model.sh silero-v5.1.2

# 暴露端口
EXPOSE 8080

# 健康检查
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8080/health || exit 1

# 启动命令
CMD ["./build/bin/whisper-server", "-m", "models/ggml-large-v3-turbo.bin", "--vad", "-vm", "models/ggml-silero-v5.1.2.bin", "--gpu-device", "0", "-t", "4", "--port", "8080"]
